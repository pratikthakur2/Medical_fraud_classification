# -*- coding: utf-8 -*-
"""fraud_detection_preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xA3RyAGcP2do6SecWFfIhs6wXxseqb2j

## **IMPORTING ALL THE NECESSARY LIBRARIES**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import os

from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder

from IPython.display import display
import datetime as dt
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
import warnings
warnings.filterwarnings("ignore")

"""## **IMPORTING THE DATA**"""

#importing datasets from google drive
from google.colab import drive
drive.mount('/content/drive')
folder_path = 'https://drive.google.com/drive/u/0/folders/1d5mA-20EVzaaFXMg9SQWlcMXf04Wbt0h'

#importing all the datasets using pandas
ben_df = pd.read_csv('/content/drive/MyDrive/medicare_fraud_detection/datasets/Train_Beneficiarydata-1542865627584.csv')
bentest_df = pd.read_csv('/content/drive/MyDrive/medicare_fraud_detection/datasets/Test_Beneficiarydata-1542969243754.csv')

inp_df = pd.read_csv('/content/drive/MyDrive/medicare_fraud_detection/datasets/Train_Inpatientdata-1542865627584.csv')
inptest_df= pd.read_csv('/content/drive/MyDrive/medicare_fraud_detection/datasets/Test_Inpatientdata-1542969243754.csv')

outp_df = pd.read_csv('/content/drive/MyDrive/medicare_fraud_detection/datasets/Train_Outpatientdata-1542865627584.csv')
outptest_df = pd.read_csv('/content/drive/MyDrive/medicare_fraud_detection/datasets/Test_Outpatientdata-1542969243754.csv')

train_1 = pd.read_csv('/content/drive/MyDrive/medicare_fraud_detection/datasets/Train-1542865627584.csv')
test_1 = pd.read_csv('/content/drive/MyDrive/medicare_fraud_detection/datasets/Test-1542969243754.csv')

"""## **DATA PREPROCESSING**

WORKING ON THE BENEFICIARY DATA
"""

#showing non null count, range, datatypes of the columns in ben_df
ben_df.info()

#Displaying the top 5 entries
ben_df.head()

#displaying the columns
ben_df.columns

#displaying the basic stats of the dataset
ben_df.describe()

#Convert DOB and DOD to datetime from object in beneficiary train data
ben_df['DOB'] = pd.to_datetime(ben_df['DOB'])
ben_df['DOD'] = pd.to_datetime(ben_df['DOD'])
ben_df.dtypes

#Convert DOB and DOD to datetime from object in beneficiary test data
bentest_df['DOB'] = pd.to_datetime(bentest_df['DOB'])
bentest_df['DOD'] = pd.to_datetime(bentest_df['DOD'])
bentest_df.dtypes

#getting the dimensions of the ben training data
ben_df.shape

#getting the dimensions of the ben testing data
bentest_df.shape

#Handle the missing values present in beneficiary train data
ben_df.isnull().sum()

#Handle the missing values present in beneficiary test data
bentest_df.isnull().sum()

#getting the datatypes of the columns
ben_df.dtypes

ben_df.head()

ben_df.shape

#Displaying the unique values and its count in the ben training data's county column
ben_df.County.value_counts()

ben_df.columns

#Replacing the values in Gender from 1,2 to 0,1 in train data
ben_df['Gender'] = ben_df['Gender'].replace({1:0,2:1})
ben_df.head()

#Replacing the values in Gender from 1,2 to 0,1 in test data
bentest_df['Gender'] = bentest_df['Gender'].replace({1:0,2:1})
bentest_df.head()

# Deleting DOD and DOB and converting it to new features 'Age' and 'Alive' in train data

ben_df['Birth_year'] = ben_df['DOB'].dt.year

#Getting the age by DOD and DOB and filling the missing values in Age column with their current age
current_date = pd.Timestamp.now()  # Get the current date
ben_df['Age'] = round(((ben_df['DOD'].fillna(current_date) - ben_df['DOB']).dt.days)/365, 0)


ben_df['Alive'] = ben_df['DOD'].apply(lambda x:1 if x!=x else 0)
ben_df.head()

# Deleting DOD and DOB and converting it to new features 'Age' and 'Alive' in test data

bentest_df['Birth_year'] = bentest_df['DOB'].dt.year

#Getting the age by DOD and DOB and filling the missing values in Age column with their current age
current_date = pd.Timestamp.now()  # Get the current date
bentest_df['Age'] = round(((bentest_df['DOD'].fillna(current_date) - bentest_df['DOB']).dt.days)/365, 0)


bentest_df['Alive'] = bentest_df['DOD'].apply(lambda x:1 if x!=x else 0)
bentest_df.head()

ben_df['Age'].value_counts()

#Displaying the unique values of the beneficiary test data's age column
bentest_df['Age'].value_counts()

#checking the datatypes after changes
ben_df.dtypes

#Checking the unique values and count of RenalDiseaseIndicator column in beneficiary train data
ben_df["RenalDiseaseIndicator"].value_counts()

#Replacing the Y values in RenalDiseaseIndicator column with 1
ben_df["RenalDiseaseIndicator"] =ben_df["RenalDiseaseIndicator"].replace({'Y':1}).astype(int)
ben_df["RenalDiseaseIndicator"].value_counts()

#Now checking the value counts after changes
bentest_df["RenalDiseaseIndicator"].value_counts()

#doing the same for the testing data
bentest_df["RenalDiseaseIndicator"] =bentest_df["RenalDiseaseIndicator"].replace({'Y':1}).astype(int)
bentest_df["RenalDiseaseIndicator"].value_counts()

#Displaying basic info of beneficiary train after changes
ben_df.info()

#Displaying basic info of beneficiary train after changes
bentest_df.info()

#checking the datatype of renal disease indicator
ben_df.RenalDiseaseIndicator.dtype

#CHRONIC PREPROCESSING for training data
#Select columns representing chronic conditions, replace occurrences of 2 with 0, and update the original DataFrame ben_df
chronic_cols_names=ben_df.columns[ben_df.columns.str.startswith("ChronicCond")]
chronic_cols=ben_df[chronic_cols_names]
chronic=chronic_cols.replace({2:0})
ben_df[chronic_cols_names]=chronic
ben_df.head()

#CHRONIC PREPROCESSING for testing data
#Select columns representing chronic conditions, replace occurrences of 2 with 0, and update the original DataFrame bentest_df
chronic_cols_names=bentest_df.columns[bentest_df.columns.str.startswith("ChronicCond")]
chronic_cols=bentest_df[chronic_cols_names]
chronic=chronic_cols.replace({2:0})
bentest_df[chronic_cols_names]=chronic
bentest_df.head()

#Creating a new dataframe which is having all the cleaned features to ben_train
ben_train = ben_df.copy()
ben_train.head()

#Doing the same for the testing data
ben_test = bentest_df.copy()
ben_test.head()

"""**INPATIENT AND OUTPATIENT DATA PREPROCESSING**"""

#Dispalying the basic info about inpatient training data
inp_df.info()

#displaying the outpatient training data basic info
outp_df.info()

#displaying the dimensions of the inpatient training data
inp_df.shape

#displaying the dimensions of the outpatient training data
outp_df.shape

#displaying the dimensions of the inpatient testing data
inptest_df.shape

#displaying the dimensions of the outpatient testing data
outptest_df.shape

#Dispalying the basic info about inpatient testing data
inptest_df.info()

#Dispalying the basic info about outpatient testing data
outptest_df.info()

#displaying the inpatiente training columns
inp_df.columns

#displaying the outpatient training data columns
outp_df.columns

#displaying the inpatient testing columns
inptest_df.columns

#displaying the outpatient testing columns
outptest_df.columns

#checking the count of null values of the inpatient testing null values
inptest_df.isna().sum()

#checking the count of null values of the outpatient testing null values
outptest_df.isna().sum()

#Merging Inpatient and outpatient train data into Train_Allpatientdata
Train_Allpatientdata=pd.merge(inp_df,outp_df,
                              left_on=['BeneID', 'ClaimID', 'ClaimStartDt', 'ClaimEndDt', 'Provider',
       'InscClaimAmtReimbursed', 'AttendingPhysician', 'OperatingPhysician',
       'OtherPhysician', 'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2',
       'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5',
       'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8',
       'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10', 'ClmProcedureCode_1',
       'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4',
       'ClmProcedureCode_5', 'ClmProcedureCode_6', 'DeductibleAmtPaid',
       'ClmAdmitDiagnosisCode'],
                              right_on=['BeneID', 'ClaimID', 'ClaimStartDt', 'ClaimEndDt', 'Provider',
       'InscClaimAmtReimbursed', 'AttendingPhysician', 'OperatingPhysician',
       'OtherPhysician', 'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2',
       'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5',
       'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8',
       'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10', 'ClmProcedureCode_1',
       'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4',
       'ClmProcedureCode_5', 'ClmProcedureCode_6', 'DeductibleAmtPaid',
       'ClmAdmitDiagnosisCode']
                              ,how='outer')

#Converting this Train_Allpatientdata dataframe to a csv named 'Train_Allpatientdata.csv'
Train_Allpatientdata.to_csv('Train_Allpatientdata.csv', index=False)

#Importing the 'Train_Allpatientdata.csv' dataset and putting into all_patients dataframe
all_patients = pd.read_csv('/content/Train_Allpatientdata.csv')

#displaying the top 5 values of the all_patients data
all_patients.head()

#merging the inpatient and outpatient test dataframes into Test_allpatientdata like the training data
Test_allpatients=pd.merge(inptest_df,outptest_df,
                              left_on=['BeneID', 'ClaimID', 'ClaimStartDt', 'ClaimEndDt', 'Provider',
       'InscClaimAmtReimbursed', 'AttendingPhysician', 'OperatingPhysician',
       'OtherPhysician', 'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2',
       'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5',
       'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8',
       'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10', 'ClmProcedureCode_1',
       'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4',
       'ClmProcedureCode_5', 'ClmProcedureCode_6', 'DeductibleAmtPaid',
       'ClmAdmitDiagnosisCode'],
                              right_on=['BeneID', 'ClaimID', 'ClaimStartDt', 'ClaimEndDt', 'Provider',
       'InscClaimAmtReimbursed', 'AttendingPhysician', 'OperatingPhysician',
       'OtherPhysician', 'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2',
       'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5',
       'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8',
       'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10', 'ClmProcedureCode_1',
       'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4',
       'ClmProcedureCode_5', 'ClmProcedureCode_6', 'DeductibleAmtPaid',
       'ClmAdmitDiagnosisCode']
                              ,how='outer')

#Converting this Test_allpatientdata dataframe to a csv named 'Test_allpatientdata.csv'
Test_allpatients.to_csv('Test_allpatients.csv', index=False)

#importing the newly created test dataset with test inpatient and test outpatient
test_allpatients = pd.read_csv('/content/Test_allpatients.csv')

#displaying the top 5 entries of test_allpatients data
test_allpatients.head()

#dim of train all patients data
all_patients.shape

#dim of test all patientsdata
test_allpatients.shape

all_patients.info()

test_allpatients.info()

all_patients.describe()

test_allpatients.describe()

#WE are imputing the missing values of DeductibleAmtPaid with mean
from sklearn.impute import SimpleImputer

# Impute missing values for numerical columns with the mean
num_imputer = SimpleImputer(strategy='mean')
num_cols = ['DeductibleAmtPaid']
all_patients[num_cols] = num_imputer.fit_transform(all_patients[num_cols])

#Now displaying the null count
all_patients.isna().sum()

#doing the same on the testing data
from sklearn.impute import SimpleImputer

# Impute missing values for numerical columns with the mean
num_imputer = SimpleImputer(strategy='mean')
num_cols = ['DeductibleAmtPaid']
test_allpatients[num_cols] = num_imputer.fit_transform(test_allpatients[num_cols])

test_allpatients.isna().sum()

#Compare physician columns and count occurrences of matching values

a=(all_patients["AttendingPhysician"]==all_patients["OperatingPhysician"])
b=(all_patients["OperatingPhysician"]==all_patients["OtherPhysician"])
c=(all_patients["AttendingPhysician"]==all_patients["OtherPhysician"])

print(a.sum())
print(b.sum())
print(c.sum())
print((a+b).sum())

#same for the testing data
a=(test_allpatients["AttendingPhysician"]==test_allpatients["OperatingPhysician"])
b=(test_allpatients["OperatingPhysician"]==test_allpatients["OtherPhysician"])
c=(test_allpatients["AttendingPhysician"]==test_allpatients["OtherPhysician"])

print(a.sum())
print(b.sum())
print(c.sum())
print((a+b).sum())

#same for testing data
def physician_same(row):
    atten_operating=row["AttendingPhysician"]==row["OperatingPhysician"]
    operating_other=row["OperatingPhysician"]==row["OtherPhysician"]
    atten_other=row["AttendingPhysician"]==row["OtherPhysician"]
    if atten_operating==True and operating_other==True:# atten = oper = other
        return 0
    elif atten_operating==True and operating_other==False:# atten = oper != other
        return 1
    elif atten_operating==False and operating_other==True:# atten != oper = other
        return 2
    else:# atten != oper != other
        return 3

phy_same=all_patients.apply(physician_same,axis=1)

#adding the new feature physame in the allpatients df
all_patients["phy_same"]=phy_same

#creating a function physician_count to count the not null values of all the physicians(attending,operating,other)
def physician_count(row,list_count):
    count=0
    for col in list_count:
        if pd.isnull(row[col]):
            continue
        else:
            count+=1
    return count

#applying this function in the test_allpatients dataset's physicians columns
list_count=["AttendingPhysician","OperatingPhysician","OtherPhysician"]
phy_count=test_allpatients.apply(physician_count,axis=1,args=(list_count,))

#adding the new feature physame in the test_allpatients df
test_allpatients["phy_same"]=phy_same

#creating a function physician_count to count the not null values of all the physicians(attending,operating,other)
def physician_count(row,list_count):
    count=0
    for col in list_count:
        if pd.isnull(row[col]):
            continue
        else:
            count+=1
    return count

#applying this function in the all_patients dataset's physicians columns
list_count=["AttendingPhysician","OperatingPhysician","OtherPhysician"]
phy_count=all_patients.apply(physician_count,axis=1,args=(list_count,))

#creating a new row of all the counts
all_patients["phy_count"]=phy_count

#displaying the top 5 entries in all_patients
all_patients.head()

#creating a function physician_count to count the not null values of all the physicians(attending,operating,other)
def physician_count(row,list_count):
    count=0
    for col in list_count:
        if pd.isnull(row[col]):
            continue
        else:
            count+=1
    return count

#applying this function in the test_allpatients dataset's physicians columns
list_count=["AttendingPhysician","OperatingPhysician","OtherPhysician"]
phy_count=test_allpatients.apply(physician_count,axis=1,args=(list_count,))

#creating a new row of all the counts
test_allpatients["phy_count"]=phy_count
#displaying the top 5 entries in test_allpatients
test_allpatients.head()

#displaying the datatypes of the all the columns in test_allpatients
test_allpatients.dtypes

#displaying the datatypes of the all the columns in all_patients
all_patients.dtypes

#Converting all the date columns with object data type to datatime
def to_date_time(df,cols):
  for col in cols:
    df[col] = pd.to_datetime(df[col])

columns_date_time = ['ClaimStartDt','ClaimEndDt','AdmissionDt','DischargeDt']
to_date_time(all_patients,columns_date_time)

all_patients[columns_date_time].dtypes

#same for the test data
to_date_time(test_allpatients,columns_date_time)

test_allpatients[columns_date_time].dtypes

#As we can see in the previous cell, the datatype of columns having dates are of object type so we convert it to datetime type
startdate= pd.to_datetime( all_patients["ClaimStartDt"] )
enddate= pd.to_datetime( all_patients["ClaimEndDt"] )

#creating a new feature named period which shows the time period between the claim start date and end date
period = (  all_patients["ClaimEndDt"] - all_patients["ClaimStartDt"]).dt.days
all_patients["period"] = period

all_patients.head()

#same for testing data
#creating a new feature named period which shows the time period between the claim start date and end date
period = (test_allpatients["ClaimEndDt"] -test_allpatients["ClaimStartDt"]).dt.days
test_allpatients["period"] = period

test_allpatients.head()

#Creating a new feature named adm_peroid containing the admission period
adm_period = ( all_patients["DischargeDt"]  - all_patients["AdmissionDt"]).dt.days
all_patients["adm_period"] = adm_period
all_patients["adm_period"]=all_patients["adm_period"].fillna(0)

all_patients.head()

#same for the testing
#Creating a new feature named adm_peroid containing the admission period
adm_period = (test_allpatients["DischargeDt"]-test_allpatients["AdmissionDt"]).dt.days
test_allpatients["adm_period"] = adm_period
test_allpatients["adm_period"]=test_allpatients["adm_period"].fillna(0)

test_allpatients.head()

"""CLEANING THE TRAIN# and TEST# data"""

train_1.shape

test_1.shape

train_1.info()

test_1.info()

train_1.PotentialFraud.value_counts()

#replacing the values in potential fraud with yes and no to 1 and 0 respectively
train_1["PotentialFraud"]=train_1["PotentialFraud"].replace({"Yes":1,"No":0})

train_1.PotentialFraud.value_counts()

"""MERGING ALL THE TRAINING DATA

# **MERGING ALL THE  DATA**

**Merging the training data**
"""

#Merging beneficiary train and all patients(inpatient and outpatient merged) on beneID
ben_allpatients_train = pd.merge(all_patients,ben_train, on="BeneID")

#merging the ben_allpatients_train and train1 to create the final training data
train_pre = pd.merge(ben_allpatients_train,train_1, on="Provider")

"""**Merging the testing data**"""

#Merging beneficiary test and test_allpatients(inpatient and outpatient merged) on beneID
ben_allpatients_test = pd.merge(test_allpatients,ben_test, on="BeneID")

ben_allpatients_test.info()

test_1.info()

#merging the ben_allpatients_test and test_1 to create the final testing data
test_pre = pd.merge(ben_allpatients_test,test_1,on="Provider")

test_pre.shape

train_pre.shape

test_pre.shape

train_pre.head()

test_pre.head()

"""# **Converting the dataframes train and test to csv for EDA**

These Datasets are not yet scaled and encoded and hence will be used for EDA
"""

train_pre.to_csv('train_eda.csv',index=False)

test_pre.to_csv('test_eda.csv',index=False)

"""Importing the preprocessed non encoded and unscaled datasets train_eda and test_eda for encoding and scaling

# **ENCODING THE CATEGORICAL VALUES**
"""

#copying the train_pre dataset to train dataframe for preparing the dataset for training
train = train_pre.copy()

#copying the test_pre dataset to test dataframe for preparing the dataset for training
test = test_pre.copy()

train.info()

train.columns

#adding the columns to encode in a list
cols_to_encode = ['BeneID', 'ClaimID','ClaimStartDt', 'ClaimEndDt', 'Provider','AttendingPhysician', 'OperatingPhysician',
       'OtherPhysician', 'AdmissionDt', 'ClmAdmitDiagnosisCode','DischargeDt', 'DiagnosisGroupCode',
       'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3',
       'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6',
       'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9',
       'ClmDiagnosisCode_10', 'ClmProcedureCode_1', 'ClmProcedureCode_2',
       'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5',
       'ClmProcedureCode_6']

#Using label encoder to encode the categorical values in training and testing data
from sklearn import preprocessing
encoder = {}
X = pd.concat([train[cols_to_encode].astype(str), test[cols_to_encode].astype(str)])
for i in cols_to_encode:
    print(i)
    encoder[i] = preprocessing.LabelEncoder()
    encoder[i].fit(X[i].astype(str))
    train[i] = encoder[i].transform(train[i].astype(str))
    test[i] = encoder[i].transform(test[i].astype(str))

train.info()

test.info()

train.head()

test.head()

"""# **SCALING THE VALUES**"""

#Using standard scalar to scale the values in a certain range

cols_to_scale = ['InscClaimAmtReimbursed', 'AttendingPhysician', 'OperatingPhysician',
       'OtherPhysician', 'ClmAdmitDiagnosisCode',
       'DeductibleAmtPaid','DiagnosisGroupCode',
       'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3',
       'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6',
       'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9',
       'ClmDiagnosisCode_10', 'ClmProcedureCode_1', 'ClmProcedureCode_2',
       'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5',
       'ClmProcedureCode_6', 'phy_same', 'phy_count', 'period', 'adm_period',
       'County', 'NoOfMonths_PartACov', 'NoOfMonths_PartBCov','IPAnnualReimbursementAmt',
       'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt',
       'OPAnnualDeductibleAmt', 'Age']
scaler = StandardScaler()

#Scaling the features in training data
train[cols_to_scale] = scaler.fit_transform(train[cols_to_scale])

#Scaling the features in testing data
test[cols_to_scale] = scaler.fit_transform(test[cols_to_scale])

#getting the top 5 entries in train to check the values in scaled data
train[cols_to_scale].head()

#plotting to see the range of some of the scaled columns
scaled_df = ['IPAnnualReimbursementAmt',
       'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt',
       'OPAnnualDeductibleAmt']
plt.figure(figsize=(15, 10))
for column in scaled_df:
    plt.hist(scaled_df, bins=20, alpha=0.5, label=column)
plt.xlabel('Scaled Value')
plt.ylabel('Frequency')
plt.title('Histograms of Scaled Columns')
plt.legend()
plt.show()

"""## **SAVING THE TRAINING AND TESTING DATA TO CSV**"""

#training data
train.to_csv('train.csv',index=False)

#testing data
test.to_csv('test.csv',index=False)